{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Classical cls-s on the winemag data were explored. "
      ],
      "metadata": {
        "id": "5XI9HG6rdlKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(0) Setup"
      ],
      "metadata": {
        "id": "381i3Z8OkPFN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bn9ALctkKZB",
        "outputId": "52659f79-feb8-4d98-e3ce-160b536f6475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wine-classifier'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 125 (delta 71), reused 60 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (125/125), 2.49 MiB | 3.36 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "/content/wine-classifier\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode==1.3.6\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bornrule==0.1.3\n",
            "  Downloading bornrule-0.1.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.3)\n",
            "Collecting scikit_learn==1.2.1\n",
            "  Downloading scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.5.0\n",
            "  Downloading spacy-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from bornrule==0.1.3->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from bornrule==0.1.3->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.1->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (0.10.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.10.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (6.3.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.0.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (8.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.0->-r requirements.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.5.0->-r requirements.txt (line 6)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.5.0->-r requirements.txt (line 6)) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.0->-r requirements.txt (line 6)) (2.1.2)\n",
            "Installing collected packages: Unidecode, tqdm, scikit_learn, bornrule, spacy\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.2\n",
            "    Uninstalling spacy-3.5.2:\n",
            "      Successfully uninstalled spacy-3.5.2\n",
            "Successfully installed Unidecode-1.3.6 bornrule-0.1.3 scikit_learn-1.2.1 spacy-3.5.0 tqdm-4.64.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kkonstantin182/wine-classifier.git\n",
        "%cd wine-classifier\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom packages\n",
        "\n",
        "import sys\n",
        "from notebooks.path_conf import get_project_root\n",
        "path_src = get_project_root() / \"src\"\n",
        "sys.path.append(str(path_src.resolve()))\n",
        "\n",
        "from src.text_processing import TextProcessing, Vectorization\n",
        "from src.dataset import Dataset\n",
        "from src.constants import SEED"
      ],
      "metadata": {
        "id": "-1WOCgmukRws"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Fi8Lu9Teuwxr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from bornrule import BornClassifier\n",
        "import multiprocessing as mp\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "# Other \n",
        "\n",
        "nltk.download('punkt') # Tokenization\n",
        "!python -m spacy download it_core_news_sm # Lemmatization, stop words\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOO32x-skWcX",
        "outputId": "63c56775-1538-4bbd-eec1-ba756f4ce57d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-09 09:34:00.038553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting it-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.5.0/it_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(I) Data"
      ],
      "metadata": {
        "id": "cAM8QgvikoYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to use\n",
        "\n",
        "COLUMNS = {\n",
        "    'target': ['type'],\n",
        "    'text': ['review', 'winery', 'variety'],\n",
        "    'numerical': ['price'],\n",
        "    'categorical': ['appellation2']\n",
        "}"
      ],
      "metadata": {
        "id": "9fKKpgFIkmqG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object for data cleaning\n",
        "# Also has tokenization inside\n",
        "\n",
        "tp_obj_clean = TextProcessing(is_lemmatized=True)\n"
      ],
      "metadata": {
        "id": "I1wJeukdkqqs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "\n",
        "train_set = pd.read_csv(get_project_root() / \"data\" / \"dataset1_train_text_cleaned.csv\", index_col=False)\n",
        "test_set = pd.read_csv(get_project_root() / \"data\" / \"dataset1_test_text_cleaned.csv\", index_col=False)\n",
        "\n",
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUYzRUmGkx1h",
        "outputId": "8ebce137-aea8-4b5d-ffb2-a4298b85db14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000, 4)\n",
            "(3000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_set.drop(\"target\", axis=1), test_set.drop(\"target\", axis=1)\n",
        "y_train, y_test = train_set['target'], test_set['target']"
      ],
      "metadata": {
        "id": "xFb7qhmbk2-H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (II) Experiments\n"
      ],
      "metadata": {
        "id": "1K8TDHUpk8mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformation pipeline\n",
        "\n",
        "# Feature trans-n\n",
        "\n",
        "num_tranfsformer = Pipeline(\n",
        "    steps=[(\"scaler\", MinMaxScaler()),\n",
        "           \n",
        "    ]\n",
        ")\n",
        "\n",
        "cat_transformer = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "# For Born Rule the input cannot be negative\n",
        "# Hence, we don't use numerical tran-s since on the test set \n",
        "# it produces negative numbers\n",
        "\n",
        "preprocessor1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", TfidfVectorizer(tokenizer=Vectorization.tokenize_it), \"text\"),\n",
        "         (\"num\", 'passthrough', COLUMNS['numerical']),\n",
        "        (\"cat\", cat_transformer, COLUMNS['categorical']),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", TfidfVectorizer(tokenizer=Vectorization.tokenize_it), \"text\"),\n",
        "         (\"num\", num_tranfsformer, COLUMNS['numerical']),\n",
        "        (\"cat\", cat_transformer, COLUMNS['categorical']),\n",
        "        \n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "6tw3cy3ek7cQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define pipelines for classifiers\n",
        "pipelines = [\n",
        "    ('Logistic Regression', Pipeline([\n",
        "        ('preprocessor', preprocessor2),\n",
        "        ('clf', LogisticRegression(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('SVM', Pipeline([\n",
        "        ('preprocessor', preprocessor2),\n",
        "        ('clf', SVC(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('Random Forest', Pipeline([\n",
        "        ('preprocessor', preprocessor2),\n",
        "        ('clf', RandomForestClassifier(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('Born Rule', Pipeline([\n",
        "        ('preprocessor', preprocessor1),\n",
        "        ('clf', BornClassifier())\n",
        "    ]))\n",
        "\n",
        "]\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "hyperparameters = {\n",
        "    'Logistic Regression': {\n",
        "        'clf__solver': ['saga'],\n",
        "        'clf__penalty': ['l1', 'l2', None],\n",
        "        'clf__C': [0.01, 0.1, 1, 10],\n",
        "    },\n",
        "\n",
        "    'SVM': {\n",
        "        'clf__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'clf__kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    \n",
        "    'Random Forest': {\n",
        "        'clf__n_estimators': [10, 100, 1000],\n",
        "        'clf__max_depth': [10, 100, None],\n",
        "        'clf__bootstrap': [True, False],\n",
        "        'clf__min_samples_split': [2, 10, 100],\n",
        "    },\n",
        "\n",
        "    'Born Rule': {\n",
        "        'clf__a': [0.25, 0.5, 1.0, 4.0], # Cannot be 0\n",
        "        'clf__b': [.0, 0.25, 0.5, 1.0, 4.0],\n",
        "        'clf__h': [.0, 0.25, 0.5, 1.0, 4.0],\n",
        "        \n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "JwGg2Uu6lVAH"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define table to store results\n",
        "# results_table = pd.DataFrame(columns=[\n",
        "#     'Classifier', \n",
        "#     'Hyperparameters', \n",
        "#     'Accuracy', \n",
        "#     'Precision', \n",
        "#     'Recall', \n",
        "#     'F1-score'])\n",
        "\n",
        "# # Train and evaluate models\n",
        "# for clf_name, pipeline in tqdm(pipelines, desc=\"Classifiers\", total=len(pipelines)):\n",
        "#     print(\"Training\", clf_name)\n",
        "#     clf = pipeline.named_steps['clf']\n",
        "#     hyperparams = hyperparameters[clf_name]\n",
        "#     # rs = RandomizedSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "#     rs = GridSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "#     rs.fit(X_train, y_train)\n",
        "    \n",
        "#     # Make predictions on train data\n",
        "#     y_pred = rs.predict(X_train)\n",
        "    \n",
        "#     # Compute metrics\n",
        "#     accuracy = accuracy_score(y_train, \n",
        "#                               y_pred)\n",
        "#     precision,recall,fscore,support=precision_recall_fscore_support(y_train, \n",
        "#                                                                     y_pred,\n",
        "#                                                                     average='macro')\n",
        "\n",
        "#     # Store results in table\n",
        "#     results_table = results_table.append({\n",
        "#         'Classifier': clf_name,\n",
        "#         'Hyperparameters': rs.best_params_,\n",
        "#         'Accuracy': accuracy,\n",
        "#         'Precision': precision,\n",
        "#         'Recall': recall,\n",
        "#         'F1-score': fscore\n",
        "#     }, ignore_index=True)\n",
        "    \n",
        "#     # Print progress bar\n",
        "#     remaining_iters = len(pipelines) - (pipelines.index((clf_name, pipeline)) + 1)\n",
        "#     print(f\"{remaining_iters} iterations left\")\n",
        "#     print(\"---------------------------------------------------------\")\n",
        "\n",
        "#     # print(report)\n",
        "\n",
        "# # Keep in mind that by default refit = True\n",
        "# # So, all metrics in the table are for the best found parameters \n",
        "\n",
        "# # Print final results table\n",
        "# print(\"\\nResults table:\")\n",
        "# print(results_table)\n",
        "# results_table.to_csv('class_cls_hp_results.csv')\n",
        "# files.download('class_cls_hp_results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "kmtOXqD2oQv2",
        "outputId": "5e00511c-b39a-4bc1-b808-68fdb5f48433"
      },
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rClassifiers:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Logistic Regression\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "<ipython-input-43-658e7fbd3d6d>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  25%|██▌       | 1/4 [04:05<12:16, 245.58s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 iterations left\n",
            "---------------------------------------------------------\n",
            "Training SVM\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-43-658e7fbd3d6d>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  50%|█████     | 2/4 [18:27<20:16, 608.12s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-43-658e7fbd3d6d>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  75%|███████▌  | 3/4 [27:54<09:49, 589.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Born Rule\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-43-658e7fbd3d6d>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers: 100%|██████████| 4/4 [30:08<00:00, 452.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 iterations left\n",
            "---------------------------------------------------------\n",
            "\n",
            "Results table:\n",
            "            Classifier                                    Hyperparameters  \\\n",
            "0  Logistic Regression  {'clf__solver': 'saga', 'clf__penalty': 'l1', ...   \n",
            "1                  SVM             {'clf__kernel': 'linear', 'clf__C': 1}   \n",
            "2        Random Forest  {'clf__n_estimators': 1000, 'clf__min_samples_...   \n",
            "3            Born Rule    {'clf__h': 0.25, 'clf__b': 1.0, 'clf__a': 0.25}   \n",
            "\n",
            "   Accuracy  Precision    Recall  F1-score  \n",
            "0  0.999750   0.999694  0.999679  0.999686  \n",
            "1  0.997333   0.995755  0.992626  0.994179  \n",
            "2  1.000000   1.000000  1.000000  1.000000  \n",
            "3  0.954250   0.849033  0.972958  0.880694  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6f41c4bd-0c8d-439a-be97-16ea208b4e7d\", \"class_cls_hp_results.csv\", 601)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define table to store results\n",
        "results_table = pd.DataFrame(columns=[\n",
        "    'Classifier', \n",
        "    'Hyperparameters', \n",
        "    'Train Accuracy', \n",
        "    'Train Precision', \n",
        "    'Train Recall', \n",
        "    'Train F1-score',\n",
        "    'Test Accuracy', \n",
        "    'Test Precision', \n",
        "    'Test Recall', \n",
        "    'Test F1-score'])\n",
        "\n",
        "# Train and evaluate models\n",
        "for clf_name, pipeline in tqdm(pipelines, desc=\"Classifiers\", total=len(pipelines)):\n",
        "    print(\"Training\", clf_name)\n",
        "    clf = pipeline.named_steps['clf']\n",
        "    hyperparams = hyperparameters[clf_name]\n",
        "    rs = RandomizedSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    # rs = GridSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    rs.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on train data\n",
        "    y_train_pred = rs.predict(X_train)\n",
        "    \n",
        "    # Compute metrics on train data\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    train_precision, train_recall, train_fscore, train_support = precision_recall_fscore_support(y_train, y_train_pred, average='macro')\n",
        "    \n",
        "    # Make predictions on test data\n",
        "    y_test_pred = rs.predict(X_test)\n",
        "    \n",
        "    # Compute metrics on test data\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_precision, test_recall, test_fscore, test_support = precision_recall_fscore_support(y_test, y_test_pred, average='macro')\n",
        "\n",
        "    # Store results in table\n",
        "    results_table = results_table.append({\n",
        "        'Classifier': clf_name,\n",
        "        'Hyperparameters': rs.best_params_,\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Train F1-score': train_fscore,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Test Precision': test_precision,\n",
        "        'Test Recall': test_recall,\n",
        "        'Test F1-score': test_fscore\n",
        "    }, ignore_index=True)\n",
        "    \n",
        "    # Print progress bar\n",
        "    remaining_iters = len(pipelines) - (pipelines.index((clf_name, pipeline)) + 1)\n",
        "    print(f\"{remaining_iters} iterations left\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "\n",
        "# Keep in mind that by default refit = True\n",
        "# So, all metrics in the table are for the best found parameters \n",
        "  \n",
        "# Print final results table\n",
        "print(\"\\nResults table:\")\n",
        "print(results_table)\n",
        "results_table.to_csv('class_cls_hp_results.csv')\n",
        "files.download('class_cls_hp_results.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "c5FTJqXe9VOW",
        "outputId": "37b5f5d2-e18b-4bc6-ec7e-85a4ee606079"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifiers:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "<ipython-input-47-74152a6873e9>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  25%|██▌       | 1/4 [03:59<11:59, 239.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 iterations left\n",
            "---------------------------------------------------------\n",
            "Training SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-47-74152a6873e9>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  50%|█████     | 2/4 [18:37<20:30, 615.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-47-74152a6873e9>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  75%|███████▌  | 3/4 [28:51<10:14, 614.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Born Rule\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-47-74152a6873e9>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers: 100%|██████████| 4/4 [31:10<00:00, 467.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 iterations left\n",
            "---------------------------------------------------------\n",
            "\n",
            "Results table:\n",
            "            Classifier                                    Hyperparameters  \\\n",
            "0  Logistic Regression  {'clf__solver': 'saga', 'clf__penalty': 'l1', ...   \n",
            "1                  SVM             {'clf__kernel': 'linear', 'clf__C': 1}   \n",
            "2        Random Forest  {'clf__n_estimators': 1000, 'clf__min_samples_...   \n",
            "3            Born Rule   {'clf__h': 0.25, 'clf__b': 0.25, 'clf__a': 0.25}   \n",
            "\n",
            "   Train Accuracy  Train Precision  Train Recall  Train F1-score  \\\n",
            "0        0.999750         0.999694      0.999679        0.999686   \n",
            "1        0.997333         0.995755      0.992626        0.994179   \n",
            "2        1.000000         1.000000      1.000000        1.000000   \n",
            "3        0.959500         0.975530      0.761481        0.787904   \n",
            "\n",
            "   Test Accuracy  Test Precision  Test Recall  Test F1-score  \n",
            "0       0.987333        0.980691     0.957183       0.968396  \n",
            "1       0.988333        0.979342     0.955803       0.967044  \n",
            "2       0.983333        0.984706     0.917910       0.946056  \n",
            "3       0.942333        0.962511     0.709813       0.717049  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_05544e61-9a65-44e7-8186-68a617890220\", \"class_cls_hp_results.csv\", 983)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "9NeZ_r4G2jU1",
        "outputId": "e89d66ee-bb0b-468b-9f87-921fd9a8c4cc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Classifier                                    Hyperparameters  \\\n",
              "0  Logistic Regression  {'clf__solver': 'saga', 'clf__penalty': 'l1', ...   \n",
              "1                  SVM             {'clf__kernel': 'linear', 'clf__C': 1}   \n",
              "2        Random Forest  {'clf__n_estimators': 1000, 'clf__min_samples_...   \n",
              "3            Born Rule   {'clf__h': 0.25, 'clf__b': 0.25, 'clf__a': 0.25}   \n",
              "\n",
              "   Train Accuracy  Train Precision  Train Recall  Train F1-score  \\\n",
              "0        0.999750         0.999694      0.999679        0.999686   \n",
              "1        0.997333         0.995755      0.992626        0.994179   \n",
              "2        1.000000         1.000000      1.000000        1.000000   \n",
              "3        0.959500         0.975530      0.761481        0.787904   \n",
              "\n",
              "   Test Accuracy  Test Precision  Test Recall  Test F1-score  \n",
              "0       0.987333        0.980691     0.957183       0.968396  \n",
              "1       0.988333        0.979342     0.955803       0.967044  \n",
              "2       0.983333        0.984706     0.917910       0.946056  \n",
              "3       0.942333        0.962511     0.709813       0.717049  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4284fd6b-068d-456e-908a-1d920604b8db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hyperparameters</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Train F1-score</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>{'clf__solver': 'saga', 'clf__penalty': 'l1', ...</td>\n",
              "      <td>0.999750</td>\n",
              "      <td>0.999694</td>\n",
              "      <td>0.999679</td>\n",
              "      <td>0.999686</td>\n",
              "      <td>0.987333</td>\n",
              "      <td>0.980691</td>\n",
              "      <td>0.957183</td>\n",
              "      <td>0.968396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM</td>\n",
              "      <td>{'clf__kernel': 'linear', 'clf__C': 1}</td>\n",
              "      <td>0.997333</td>\n",
              "      <td>0.995755</td>\n",
              "      <td>0.992626</td>\n",
              "      <td>0.994179</td>\n",
              "      <td>0.988333</td>\n",
              "      <td>0.979342</td>\n",
              "      <td>0.955803</td>\n",
              "      <td>0.967044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'clf__n_estimators': 1000, 'clf__min_samples_...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.983333</td>\n",
              "      <td>0.984706</td>\n",
              "      <td>0.917910</td>\n",
              "      <td>0.946056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Born Rule</td>\n",
              "      <td>{'clf__h': 0.25, 'clf__b': 0.25, 'clf__a': 0.25}</td>\n",
              "      <td>0.959500</td>\n",
              "      <td>0.975530</td>\n",
              "      <td>0.761481</td>\n",
              "      <td>0.787904</td>\n",
              "      <td>0.942333</td>\n",
              "      <td>0.962511</td>\n",
              "      <td>0.709813</td>\n",
              "      <td>0.717049</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4284fd6b-068d-456e-908a-1d920604b8db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4284fd6b-068d-456e-908a-1d920604b8db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4284fd6b-068d-456e-908a-1d920604b8db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAwWQe2FXJVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}