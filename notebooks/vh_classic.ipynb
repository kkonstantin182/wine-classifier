{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XI9HG6rdlKA"
      },
      "source": [
        "Classical cls-s on the winemag data were explored. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381i3Z8OkPFN"
      },
      "source": [
        "(0) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bn9ALctkKZB",
        "outputId": "58bc72f2-5b5f-42d6-86f8-79ff6f481a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wine-classifier'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (142/142), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 142 (delta 79), reused 75 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (142/142), 2.68 MiB | 5.53 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "/content/wine-classifier\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Unidecode==1.3.6 (from -r requirements.txt (line 1))\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bornrule==0.1.3 (from -r requirements.txt (line 2))\n",
            "  Downloading bornrule-0.1.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.3)\n",
            "Collecting scikit_learn==1.2.1 (from -r requirements.txt (line 5))\n",
            "  Downloading scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.5.0 (from -r requirements.txt (line 6))\n",
            "  Downloading spacy-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r requirements.txt (line 7))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from bornrule==0.1.3->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from bornrule==0.1.3->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.1->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (6.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.0->-r requirements.txt (line 6)) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.5.0->-r requirements.txt (line 6)) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.0->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.5.0->-r requirements.txt (line 6)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.5.0->-r requirements.txt (line 6)) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.0->-r requirements.txt (line 6)) (2.1.2)\n",
            "Installing collected packages: Unidecode, tqdm, scikit_learn, bornrule, spacy\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.2\n",
            "    Uninstalling spacy-3.5.2:\n",
            "      Successfully uninstalled spacy-3.5.2\n",
            "Successfully installed Unidecode-1.3.6 bornrule-0.1.3 scikit_learn-1.2.1 spacy-3.5.0 tqdm-4.64.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kkonstantin182/wine-classifier.git\n",
        "%cd wine-classifier\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1WOCgmukRws"
      },
      "outputs": [],
      "source": [
        "# Custom packages\n",
        "\n",
        "import sys\n",
        "from notebooks.path_conf import get_project_root\n",
        "path_src = get_project_root() / \"src\"\n",
        "sys.path.append(str(path_src.resolve()))\n",
        "\n",
        "from src.text_processing import TextProcessing, Vectorization\n",
        "from src.dataset import Dataset\n",
        "from src.constants import SEED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi8Lu9Teuwxr"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOO32x-skWcX",
        "outputId": "2d95c514-333c-434c-c111-7df938842c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-11 22:57:39.489364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting it-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.5.0/it_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: it-core-news-sm\n",
            "Successfully installed it-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "# Libraries\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from bornrule import BornClassifier\n",
        "import multiprocessing as mp\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "# Other \n",
        "\n",
        "nltk.download('punkt') # Tokenization\n",
        "!python -m spacy download it_core_news_sm # Lemmatization, stop words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_selector, make_column_transformer"
      ],
      "metadata": {
        "id": "My7Cjf8WoOKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAM8QgvikoYU"
      },
      "source": [
        "(I) Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fKKpgFIkmqG"
      },
      "outputs": [],
      "source": [
        "# Columns to use\n",
        "\n",
        "TARGET_MAP = {\n",
        "    # Put here the map for the target variable.\n",
        "    # Removed due to the privacy reasons.\n",
        "}\n",
        "\n",
        "COLUMNS = {\n",
        "    'target': ['character'],\n",
        "    'text': ['text'],\n",
        "    'numerical': ['alcohol', 'wine_name_length', 'n_grapes'],\n",
        "    'categorical': ['category', 'region', 'is_complex_grape', 'alcohol_level']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1wJeukdkqqs"
      },
      "outputs": [],
      "source": [
        "# Object for data cleaning\n",
        "# As the data is cleaned already, only tokenizer will be used\n",
        "\n",
        "tp_obj_clean = TextProcessing(is_lemmatized=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUYzRUmGkx1h",
        "outputId": "639eb21a-5fad-4093-f2ba-de0252b3ee03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4016, 9)\n",
            "(1005, 9)\n"
          ]
        }
      ],
      "source": [
        "# Loading data\n",
        "\n",
        "train_set = pd.read_csv(r\"/content/vh_train.csv\", index_col=False)\n",
        "test_set = pd.read_csv(r\"/content/vh_test.csv\", index_col=False)\n",
        "\n",
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqyhjpoqFgnF",
        "outputId": "79ed30ff-c233-4fcb-bb9a-4249e8aecdb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['target', 'text', 'alcohol', 'wine_name_length', 'n_grapes', 'category',\n",
              "       'region', 'is_complex_grape', 'alcohol_level'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFb7qhmbk2-H"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = train_set.drop(\"target\", axis=1), test_set.drop(\"target\", axis=1)\n",
        "y_train, y_test = train_set['target'], test_set['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K8TDHUpk8mo"
      },
      "source": [
        "# (II) Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlcoholImputer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, group_column='category', impute_column1='alcohol', impute_column2='alcohol_level'):\n",
        "\n",
        "        self.group_column = group_column\n",
        "        self.impute_column1 = impute_column1\n",
        "        self.impute_column2 = impute_column2\n",
        "        self.transformed_columns_ = []\n",
        "\n",
        "   \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = X.copy()\n",
        "        X_transformed[self.impute_column1] = X.groupby(self.group_column)[self.impute_column1].apply(lambda x: x.fillna(x.median()))\n",
        "        X_transformed[self.impute_column2] = X_transformed[self.impute_column1].apply(self.impute_alco_level)\n",
        "        self.transformed_columns_ = X_transformed.columns.difference(X.columns).tolist()\n",
        "        return pd.DataFrame(X_transformed, columns=X.columns, index=X.index)\n",
        "\n",
        "    def impute_alco_level(self, x):\n",
        "        if x < 11.5: level = 'low'\n",
        "        elif 11.5 <= x < 13.5: level = 'medium'\n",
        "        elif x >= 13.5: level = 'high'\n",
        "        else: level = np.nan\n",
        "        return level\n",
        "\n",
        "    \n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'group_column': self.group_column, \n",
        "            'impute_column1': self.impute_column1,\n",
        "            'impute_column2': self.impute_column2}\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        self.group_column = params['group_column']\n",
        "        self.impute_column1 = params['impute_column1']\n",
        "        self.impute_column2 = params['impute_column2']\n",
        "        return self\n",
        "    \n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        return self.transformed_columns_\n"
      ],
      "metadata": {
        "id": "MAXakf11qnnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN in the alcohol column\n",
        "alcohol_enc = AlcoholImputer().fit(X_train)\n",
        "X_train = alcohol_enc.transform(X_train)\n",
        "X_test = alcohol_enc.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pps-bqG7IbzX",
        "outputId": "4f4e3e27-c385-4465-8b70-e1217114e2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-10adc7537152>:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  X_transformed[self.impute_column1] = X.groupby(self.group_column)[self.impute_column1].apply(lambda x: x.fillna(x.median()))\n",
            "<ipython-input-11-10adc7537152>:15: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
            "To preserve the previous behavior, use\n",
            "\n",
            "\t>>> .groupby(..., group_keys=False)\n",
            "\n",
            "To adopt the future behavior and silence this warning, use \n",
            "\n",
            "\t>>> .groupby(..., group_keys=True)\n",
            "  X_transformed[self.impute_column1] = X.groupby(self.group_column)[self.impute_column1].apply(lambda x: x.fillna(x.median()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For all cls-s but not Born Rule\n",
        "preprocessor1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", TfidfVectorizer(tokenizer=Vectorization.tokenize_it), \"text\"),\n",
        "        (\"num\", MinMaxScaler(),  COLUMNS['numerical']),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), COLUMNS['categorical']),\n",
        "        \n",
        "    ]\n",
        ")\n",
        "\n",
        "# For Born Rule\n",
        "preprocessor2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"text\", TfidfVectorizer(tokenizer=Vectorization.tokenize_it), \"text\"),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), COLUMNS['categorical']),\n",
        "        \n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ],
      "metadata": {
        "id": "WbMriA5ZJfyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define pipelines for classifiers\n",
        "pipelines = [\n",
        "    ('Logistic Regression', Pipeline([\n",
        "        ('preprocessor1', preprocessor2),\n",
        "        ('clf', LogisticRegression(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('SVM', Pipeline([\n",
        "        ('preprocessor1', preprocessor2),\n",
        "        ('clf', SVC(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('Random Forest', Pipeline([\n",
        "        ('preprocessor1', preprocessor2),\n",
        "        ('clf', RandomForestClassifier(random_state=SEED))\n",
        "    ])),\n",
        "\n",
        "    ('Born Rule', Pipeline([\n",
        "        ('preprocessor2', preprocessor1),\n",
        "        ('clf', BornClassifier())\n",
        "    ]))\n",
        "\n",
        "]\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "hyperparameters = {\n",
        "    'Logistic Regression': {\n",
        "        'clf__solver': ['saga'],\n",
        "        'clf__penalty': ['l1', 'l2', None],\n",
        "        'clf__C': [0.01, 0.1, 1, 10],\n",
        "    },\n",
        "\n",
        "    'SVM': {\n",
        "        'clf__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'clf__kernel': ['linear', 'rbf']\n",
        "    },\n",
        "    \n",
        "    'Random Forest': {\n",
        "        'clf__n_estimators': [10, 100, 1000],\n",
        "        'clf__max_depth': [10, 100, None],\n",
        "        'clf__bootstrap': [True, False],\n",
        "        'clf__min_samples_split': [2, 10, 100],\n",
        "    },\n",
        "\n",
        "    'Born Rule': {\n",
        "        'clf__a': [0.25, 0.5, 1.0, 4.0], # Cannot be 0\n",
        "        'clf__b': [.0, 0.25, 0.5, 1.0, 4.0],\n",
        "        'clf__h': [.0, 0.25, 0.5, 1.0, 4.0],\n",
        "        \n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "qjySknabMxkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define table to store results\n",
        "results_table = pd.DataFrame(columns=[\n",
        "    'Classifier', \n",
        "    'Hyperparameters', \n",
        "    'Train Accuracy', \n",
        "    'Train Precision', \n",
        "    'Train Recall', \n",
        "    'Train F1-score',\n",
        "    'Test Accuracy', \n",
        "    'Test Precision', \n",
        "    'Test Recall', \n",
        "    'Test F1-score'])\n",
        "\n",
        "# Train and evaluate models\n",
        "for clf_name, pipeline in tqdm(pipelines, desc=\"Classifiers\", total=len(pipelines)):\n",
        "    print(\"Training\", clf_name)\n",
        "    clf = pipeline.named_steps['clf']\n",
        "    hyperparams = hyperparameters[clf_name]\n",
        "    rs = RandomizedSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    # rs = GridSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "    rs.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on train data\n",
        "    y_train_pred = rs.predict(X_train)\n",
        "    \n",
        "    # Compute metrics on train data\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    train_precision, train_recall, train_fscore, train_support = precision_recall_fscore_support(y_train, y_train_pred, average='macro')\n",
        "    \n",
        "    # Make predictions on test data\n",
        "    y_test_pred = rs.predict(X_test)\n",
        "    \n",
        "    # Compute metrics on test data\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_precision, test_recall, test_fscore, test_support = precision_recall_fscore_support(y_test, y_test_pred, average='macro')\n",
        "\n",
        "    # Store results in table\n",
        "    results_table = results_table.append({\n",
        "        'Classifier': clf_name,\n",
        "        'Hyperparameters': rs.best_params_,\n",
        "        'Train Accuracy': train_accuracy,\n",
        "        'Train Precision': train_precision,\n",
        "        'Train Recall': train_recall,\n",
        "        'Train F1-score': train_fscore,\n",
        "        'Test Accuracy': test_accuracy,\n",
        "        'Test Precision': test_precision,\n",
        "        'Test Recall': test_recall,\n",
        "        'Test F1-score': test_fscore\n",
        "    }, ignore_index=True)\n",
        "    \n",
        "    # Print progress bar\n",
        "    remaining_iters = len(pipelines) - (pipelines.index((clf_name, pipeline)) + 1)\n",
        "    print(f\"{remaining_iters} iterations left\")\n",
        "    print(\"---------------------------------------------------------\")\n",
        "\n",
        "# Keep in mind that by default refit = True\n",
        "# So, all metrics in the table are for the best found parameters \n",
        "  \n",
        "# Print final results table\n",
        "print(\"\\nResults table:\")\n",
        "print(results_table)\n",
        "results_table.to_csv('vh_class_cls_hp_results.csv')\n",
        "files.download('vh_class_cls_hp_results.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rS7O_s6tNYJ_",
        "outputId": "b690058f-ad0f-4ba5-e0b5-c91f66dee602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rClassifiers:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-41-d05709a72344>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  25%|██▌       | 1/4 [03:30<10:31, 210.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 iterations left\n",
            "---------------------------------------------------------\n",
            "Training SVM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "<ipython-input-41-d05709a72344>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  50%|█████     | 2/4 [09:47<10:17, 308.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Random Forest\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-41-d05709a72344>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers:  75%|███████▌  | 3/4 [13:18<04:23, 263.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 iterations left\n",
            "---------------------------------------------------------\n",
            "Training Born Rule\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-41-d05709a72344>:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\n",
            "Classifiers: 100%|██████████| 4/4 [13:50<00:00, 207.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 iterations left\n",
            "---------------------------------------------------------\n",
            "\n",
            "Results table:\n",
            "            Classifier                                    Hyperparameters  \\\n",
            "0  Logistic Regression  {'clf__solver': 'saga', 'clf__penalty': 'l2', ...   \n",
            "1                  SVM             {'clf__kernel': 'linear', 'clf__C': 1}   \n",
            "2        Random Forest  {'clf__n_estimators': 100, 'clf__min_samples_s...   \n",
            "3            Born Rule      {'clf__h': 1.0, 'clf__b': 0.5, 'clf__a': 1.0}   \n",
            "\n",
            "   Train Accuracy  Train Precision  Train Recall  Train F1-score  \\\n",
            "0        0.576942         0.564503      0.477074        0.469817   \n",
            "1        0.869273         0.907208      0.877787        0.890405   \n",
            "2        0.995269         0.995644      0.988529        0.991907   \n",
            "3        0.505727         0.515209      0.419817        0.365845   \n",
            "\n",
            "   Test Accuracy  Test Precision  Test Recall  Test F1-score  \n",
            "0       0.536318        0.531377     0.444078       0.430960  \n",
            "1       0.615920        0.609857     0.576258       0.584171  \n",
            "2       0.602985        0.607708     0.535319       0.544353  \n",
            "3       0.472637        0.464010     0.392031       0.325513  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_377b95cc-6282-47eb-a5e6-30acb60568d1\", \"vh_class_cls_hp_results.csv\", 1062)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "oLWpCUCPNcrb",
        "outputId": "cbc3ca24-7ebd-4780-fcfb-26857a712256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Classifier                                    Hyperparameters  \\\n",
              "0  Logistic Regression  {'clf__solver': 'saga', 'clf__penalty': 'l2', ...   \n",
              "1                  SVM             {'clf__kernel': 'linear', 'clf__C': 1}   \n",
              "2        Random Forest  {'clf__n_estimators': 100, 'clf__min_samples_s...   \n",
              "3            Born Rule      {'clf__h': 1.0, 'clf__b': 0.5, 'clf__a': 1.0}   \n",
              "\n",
              "   Train Accuracy  Train Precision  Train Recall  Train F1-score  \\\n",
              "0        0.576942         0.564503      0.477074        0.469817   \n",
              "1        0.869273         0.907208      0.877787        0.890405   \n",
              "2        0.995269         0.995644      0.988529        0.991907   \n",
              "3        0.505727         0.515209      0.419817        0.365845   \n",
              "\n",
              "   Test Accuracy  Test Precision  Test Recall  Test F1-score  \n",
              "0       0.536318        0.531377     0.444078       0.430960  \n",
              "1       0.615920        0.609857     0.576258       0.584171  \n",
              "2       0.602985        0.607708     0.535319       0.544353  \n",
              "3       0.472637        0.464010     0.392031       0.325513  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd1aa38c-276d-4cd2-87ab-4308f226e1c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Hyperparameters</th>\n",
              "      <th>Train Accuracy</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Train F1-score</th>\n",
              "      <th>Test Accuracy</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>{'clf__solver': 'saga', 'clf__penalty': 'l2', ...</td>\n",
              "      <td>0.576942</td>\n",
              "      <td>0.564503</td>\n",
              "      <td>0.477074</td>\n",
              "      <td>0.469817</td>\n",
              "      <td>0.536318</td>\n",
              "      <td>0.531377</td>\n",
              "      <td>0.444078</td>\n",
              "      <td>0.430960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVM</td>\n",
              "      <td>{'clf__kernel': 'linear', 'clf__C': 1}</td>\n",
              "      <td>0.869273</td>\n",
              "      <td>0.907208</td>\n",
              "      <td>0.877787</td>\n",
              "      <td>0.890405</td>\n",
              "      <td>0.615920</td>\n",
              "      <td>0.609857</td>\n",
              "      <td>0.576258</td>\n",
              "      <td>0.584171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>{'clf__n_estimators': 100, 'clf__min_samples_s...</td>\n",
              "      <td>0.995269</td>\n",
              "      <td>0.995644</td>\n",
              "      <td>0.988529</td>\n",
              "      <td>0.991907</td>\n",
              "      <td>0.602985</td>\n",
              "      <td>0.607708</td>\n",
              "      <td>0.535319</td>\n",
              "      <td>0.544353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Born Rule</td>\n",
              "      <td>{'clf__h': 1.0, 'clf__b': 0.5, 'clf__a': 1.0}</td>\n",
              "      <td>0.505727</td>\n",
              "      <td>0.515209</td>\n",
              "      <td>0.419817</td>\n",
              "      <td>0.365845</td>\n",
              "      <td>0.472637</td>\n",
              "      <td>0.464010</td>\n",
              "      <td>0.392031</td>\n",
              "      <td>0.325513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd1aa38c-276d-4cd2-87ab-4308f226e1c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd1aa38c-276d-4cd2-87ab-4308f226e1c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd1aa38c-276d-4cd2-87ab-4308f226e1c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yrXbwOMGRkNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}