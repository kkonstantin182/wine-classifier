{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from path_conf import get_project_root\n",
    "path_src = get_project_root() / \"src\"\n",
    "sys.path.append(str(path_src.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing import TextProcessing\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"E:\\OneDrive\\Documents\\GitHub\\wine-classifier\\data\\dataset1_proc.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MAP = {\n",
    "    'Rosato': 0, \n",
    "    'Frizzante': 1, \n",
    "    'Bianco': 2, \n",
    "    'Rosso': 3\n",
    "}\n",
    "\n",
    "COLUMNS = {\n",
    "    'target': ['type'],\n",
    "    'text': ['review', 'winery', 'variety'],\n",
    "    'numerical': ['price'],\n",
    "    'categorical': ['appellation2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Dataset.print_shape of <dataset.Dataset object at 0x00000290D8EC3D60>>\n"
     ]
    }
   ],
   "source": [
    "ds_obj = Dataset(data_path, target_map=TARGET_MAP, columns_names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape: (12000, 4)\n",
      "The test shape: (3000, 4)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = ds_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14109    3\n",
       "6673     3\n",
       "11845    3\n",
       "2738     2\n",
       "11414    3\n",
       "        ..\n",
       "3875     2\n",
       "14654    3\n",
       "8081     3\n",
       "276      0\n",
       "10863    3\n",
       "Name: type, Length: 12000, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_set.drop(\"type\", axis=1), test_set.drop(\"type\", axis=1)\n",
    "y_train, y_test = train_set['type'], test_set['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessor for the pipeline\n",
    "tfidf_transformer = TfidfVectorizer()\n",
    "onehot_transformer = OneHotEncoder()\n",
    "num_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', tfidf_transformer, 'text'),\n",
    "    ('onehot', onehot_transformer, ['categorical']),\n",
    "    ('num', num_transformer, ['numerical'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define pipelines for classifiers\n",
    "pipelines = [\n",
    "    ('Logistic Regression', Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', LogisticRegression(random_state=42))\n",
    "    ])),\n",
    "    ('SVM', Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', SVC(random_state=42))\n",
    "    ])),\n",
    "    ('Random Forest', Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "hyperparameters = {\n",
    "    'Logistic Regression': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [10, 20, None]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define table to store results\n",
    "results_table = pd.DataFrame(columns=['Classifier', 'Hyperparameters', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "# Train and evaluate models\n",
    "for clf_name, pipeline in pipelines:\n",
    "    print(\"Training\", clf_name)\n",
    "    clf = pipeline.named_steps['clf']\n",
    "    hyperparams = hyperparameters[clf_name]\n",
    "    rs = RandomizedSearchCV(pipeline, hyperparams, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    rs.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_pred = rs.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    precision, recall, f1, _ = map(float, report.split(\"\\n\")[-2].split()[1:])\n",
    "    \n",
    "    # Store results in table\n",
    "    results_table = results_table.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Hyperparameters': rs.best_params_,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-score': f1\n",
    "    }, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
